\section[Критерий Пирсона (лекция 11)]{Непараметрические гипотезы. Критерий согласия $\chi^2$ Пирсона. Проверка гипотезы о виде распределения}

\epigraph{\emph{Лекция 11} (15.11.2023)}

Рассмотрим простую гипотезу $H_0: X_1, \dots, X_n \sim F(x)$,
где $F(x)$ --- конкретная функция распределения, например $\mathscr N(0, 1)$
или
$\mathscr R[0, 2]$, с плотностью $ p $.
И альтернативу к ней \emph{$H_1$: выборка не подчиняется $F(x)$}.

Сгруппируем выборку.
\begin{center}
  \begin{tabular}{|c|c|c|c|c|}
    \hline
    Интервалы выборки & $E_1$ & $E_2$ & \dots & $E_n$ \\
    \hline 
    Эмпирические частоты & $\nu_1$ & $\nu_2$ & \dots & $\nu_n$ \\
    \hline 
    Частоты $ H_0 $ & $np_1$ & $np_2$ & \dots & $np_n$ \\
    \hline
  \end{tabular}
\end{center}
\begin{remark*}
  Интервалы группировки представляют собой разбиения области значений случайной
  величины. В дискретном случае они являются некоторым набором значений, а в
  непрерывном --- промежутом числовой прямой. В примере ниже они разбивают всё
  вероятностное пространство.
\end{remark*}

Будем проверять схожесть двух последних строк.
Для оценки схожести вводятся различные метрики, Пирсон придумал достаточно удачную метрику
\[
  \chi^2_B = \sum_{k=1}^m \frac{(\nu_k - np_k)^2}{np_k}.
\]

\begin{theorem}[Пирсона для простых гипотез]
  %!! простая гипотеза означает, что закон распределения очень конкретный (без параметра)

  Пусть $E$ --- множество значений $X_i$ представлено в виде $E =
  \bigsqcup\limits_{i=1}^m E_i$
  (объединение непересекающихся множеств $E_i \cap E_j = \varnothing$, $i \neq
  j$).

  Пусть $p_i = P_0 (X_i \in E_i)$, $\nu_i$ - частоты попадения в $E_i$. Тогда
  \[
    \chi^2_B = \sum_{k=1}^m \frac{(\nu_i - np_i)^2}{np_i} \toD \chi^2 (m-1),
    \quad n \to \infty.
  \]
  
\end{theorem}

\begin{proof}
  Напомним определение \emph{характеристической функции}.
  \[
    f_\xi (t) = M e^{i t \xi},\qquad f_{\bm\xi} = M e^{i (\mathbf t, \bm \xi)} =
    M e^{i \sum t_k \xi_k}.
  \]
В доказательстве будут использоваться следующие случайные величины:
\begin{enumerate}
  \item Статистика $ \bm \nu = (\nu_1, \nu_2, \ldots, \nu_m)^T$, распределённая
    полиномиально. Действительно, отождествляя попадание величины $ X_i $ в
    интервал $ E_j $ с вектором $ \mathbf e(X_i) = \mathbf e_j $,
    получим $ \bm \nu = \sum \mathbf e(X_i) $. Напомним вероятности этого
    закона: 
      \[
    P(\bm\nu = (n_1, n_2, \dots, n_m)) = \frac{n!}{n_1! n_2! \dots n_m!}
    p_1^{n_1} p_2^{n_2} \dots p_m^{n_m}, 
  \]
  где, разумеется, $\sum n_i = n$, а
  \[
    \sum \frac{n!}{n_1! n_2! \dots n_m!} p_1^{n_1} \dots p_m^{n_m} = (p_1 + p_2
    + \ldots + p_m)^n = 1
  \]
  по свойству мультиномиальных коэффициентов.
    
  \item Случайный вектор
  \[
  \bm\eta = \left\{\frac{\nu_i - np_i}{\sqrt{np_i}}\right\},
  \]
  который является функцией от $ \bm \nu $. Важно заметить, что его скалярный
  квадрат (квадрат длины) и будет равен статистике $ \chi^2_B $.
\item Наконец, случайный вектор $ \bm \xi = C \nu $, где $ C $ --- некоторая
  ортогональная матрица с заданной первой строчкой (одну единичную строку можно задать в
  любой ортогональной матрице): 
  \[
    C = \begin{pmatrix}
      \sqrt{p_1} & \cdots & \sqrt{p_m} \\
      \vdots & \ddots & \vdots \\
      \cdots & \cdots & \cdots
    \end{pmatrix}.
  \]
  
  
\end{enumerate}


  При нулевой гипотезе
  \[
    p_i = P_0 (\xi \in E_i)
  \]

  Ясно, что это распределено по полиномиальному закону:
  \[
    P(\bar \nu = (n_1, n_2, \dots, n_m)) = \frac{n!}{n_1! n_2! \dots n_m!} p_1^{n_1} p_2^{n_2} \dots p_m^{n_m}, \sum n_i = n
  \]

  \[
    \sum \frac{n!}{n_1! n_2! \dots n_m!} p_1^{n_1} \dots p_m^{n_m} = 1
  \]

  \begin{multline*}
    f_{\bar \nu} (\bar t) = M e^{i \bar t^T \bar \nu} =
    \sum e^{i \sum t_k n_k} \frac{n!}{n_1! n_2! \dots n_m!} p_1^{n_1} \dots p_m^{n_m} = \\
    = \sum \frac{n!}{n_1! n_2! \dots n_m!} (p_1 e^{i t_1})^{n_1} (p_2 e^{i t_2})^{n_2} \dots (p_m e^{i t_m})^{n_m} = 
    (p_1 e^{i t_1} + p_2 e^{i t_2} + \dots + p_m e^{i t_m})^n = \\
    = (1 + p_1 (e^{i t_1} - 1) + p_2 (e^{i t_2} - 1) + \dots + p_m (e^{i t_m} - 1))^n
  \end{multline*}

  \[
    \ln f_{\bar \nu} (\bar t) = n \ln (1 + p_1 (e^{i t_1} - 1) + p_2 (e^{i t_2} - 1) + \dots + p_m (e^{i t_m} - 1))
  \]

  Обозначим
  \[
    \eta_k = \frac{\nu_k - np_k}{\sqrt{np_k}}, \chi^2_B = \sum_{k=1}^m \eta_k^2
  \]

  Тогда
  \[
    f_{\bar \eta} (\bar t) = M e^{i \bar t^T \bar \eta} =
    M e^{i \sum t_k \frac{\nu_k - np_k}{\sqrt{np_k}}} = 
    M e^{i \sum \frac{t_k}{\sqrt{np_k}} \nu_k} \cdot e^{i \sum t_k \sqrt{np_k}} = 
    f_{\bar \nu} (\frac{t_1}{\sqrt{np_1}}, \dots, \frac{t_m}{\sqrt{np_m}}) e^{i \sum t_k \sqrt{np_k}}
  \]

  Тогда
  \[
    \ln f_{\bar \eta} (\bar t) = -i \sum t_k \sqrt{np_k} + n \ln (1+p_1 (e^{\frac{i t_1}{\sqrt{np_1}}} - 1)+ \dots + p_m (e^{\frac{i t_m}{\sqrt{np_m}}} - 1) )
  \]

  Используя эквивалентности,
  \begin{multline*}
    = -i \sum t_k \sqrt{np_k} + n \left( \sum p_k \left(e^{\frac{i t_k}{\sqrt{np_k}}}
    - 1\right) - \frac{1}{2} \left(\sum p_k(e^{\frac{i t_k}{\sqrt{np_k}}} - 1)\right)^2 +
  o\left(\frac{1}{n}\right) \right) = \\
    = -i \sum t_k \sqrt{np_k} + n \left( \sum p_k \left(\frac{i t_k}{\sqrt{np_k}} +
    \frac{1}{2} \sum \frac{i t_k}{\sqrt{np_k}}\right)^2 - \frac{1}{2} \left(\sum p_k
  \frac{i t_k}{\sqrt{np_K}}\right)^2 + o\left(\frac{1}{n}\right) \right) = \\
    = - \frac{1}{2} \sum t_k^2 + \frac{1}{2} \left( \sum t_k \sqrt{p_k}
    \right)^2 + o\left(\frac{1}{n}\right)
    = - \frac{1}{2} \bar t^T \bar t + \frac{1}{2} ((C \bar t)_1)^2 + o(1),
  \end{multline*}
  где $C$ - ортогональное преобразование $\bm \xi = C \bm\eta$, с первой
  строчкой $(\sqrt{p_1}, \dots, \sqrt{p_m})$,
    а индексом 1 в $(C \bar t)_1$ обозначено взятие первого элемента вектора.

  Рассмотрим, что происходит с характеристической функцией при ортогональных преобразованиях:
  \[
    f_{C\bm\eta} = f_{\bm \xi} (\mathbf t) = M e^{i \mathbf t^T \bm \xi} = M e^{i \mathbf t^T C
    \bm\eta} =
    M e^{i (C^T \mathbf t)^T \bm \eta} = f_{\bm\eta} (C^T \mathbf t).
  \]

  \[
    \ln f_{\bar \xi} (\bar t) = - \frac{1}{2} (C^T \bar t)^T C^T \bar t + \frac{1}{2} ((C C^T \bar t))^2 + o(1) = -\frac{1}{2} \bar t^T \bar t + \frac{1}{2} t_1^2 + o(1) = - \frac{1}{2} \sum_{k=2}^m t_k^2 + o(1)
  \]

  \[
    \chi^2_B = \sum \frac{(\nu_k - np_k)^2}{np_k} = \sum \eta_k^2 = \bar \xi^T C^T C \bar \xi = \sum \xi_k^2
  \]

  Рассмотрим как распределен вектор $\bar \xi$:
  
  Если бы $\bar \xi \sim N(0, \Sigma)$, то:
  \[
    (\xi_1, \dots, \xi_m) \sim N(0, \Sigma) \Leftrightarrow f_{\bar \xi} (\bar t) = e^{-\frac{1}{2} \sum \sigma_k^2 t_k^2}
  \]

  В нашей ситуации выходит, что $\sigma_1 = 0$, следовательно, $\sum \xi_k^2 \sim \chi^2 (m-1)$.
\end{proof}

\begin{remark*} 
  Пусть $np_k$ достаточно большие (на практике $np_k \geqslant
5$). Если это не так, то не выполняются предельные условия в теореме (хотя бы
условия ЦПТ). В этом случае следует объединять интервалы $E_k$ с соседними.
\end{remark*}

Наконец, сформулируем критерий:
\begin{itemize}[label=---]
  \item если $\chi^2_B \geqslant \chi^2_{1-\alpha} (m-1)$, то $H_0$ отклоняем,
  \item если $\chi^2_B < \chi^2_{1-\alpha}(m-1)$, то $H_0$ принимаем.
\end{itemize}

\begin{ex}[Мендель]
  556 горошин скрещивали во втором поколении.
  В первом поколении все оказались жёлтыми.
  Доминантный ген означает, что если от родителей достались два разных гена,
  то проявляться будет именно доминантный. Введём следующие обозначения: К ---
  круглая горошина; М --- морщинистая горошина; Ж --- жёлтая горошина; З ---
  зелёная горошина.
  
  \begin{center}
    \begin{tabular}{|c|c|c|c|c|}
      \hline
       Интервалы разбиения & КЖ & КЗ & МЖ & МЗ \\
      \hline
      Эмпирические частоты & 315 & 108 & 101 & 32 \\
      \hline
      Частоты $np_k$ & $\frac{9\cdot 556}{16}$ & $\frac{3\cdot 556}{16}$ &
      $\frac{3\cdot 556}{16}$ & \vphantom{\biggl|}$\frac{556}{16}$ \\
      \hline
    \end{tabular}
  \end{center}

  $H_0$ --- гипотеза о том, что признаки цвета и формы независимы, а круглая
  форма и желтый цвет --- доминантные признаки.

  Посчитаем $\chi^2_B$ и применим критерий:
  \[
    \chi^2_B = \sum_{i=1}^4 \frac{(v_i - np_i)^2}{np_i} = \frac{2.25^2}{312.75}
    + \ldots + \frac{2.75^2}{34.75} = 0.47 < \chi^2_{0.9} (3) = 6.25.
  \]
  Таким образом, заключаем, что гипотеза $H_0$ подтверждается.
\end{ex}
