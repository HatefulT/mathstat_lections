\section{Условное математическое ожидание относительно $\sigma$-алгебры и его свойства}
На данный момент мы знаем, что 
\begin{multline*}
  M(\eta \mid \xi) \equiv M(\eta \mid \xi = x) \Big|_{x = \xi}
  = \int\limits_{-\infty}^{+\infty} y p_{\eta} (y \mid \xi = x) \, dy \bigg|_{x = \xi}
  = \\ =
  \int\limits_{-\infty}^{+\infty} y \dfrac{p_{\xi\eta} (x, y)}{p_\xi (x)} \,
  dy\biggl|_{x=\xi} = \frac{\int\limits_{-\infty}^{\infty}y p_{\xi\eta}(x,
  y)\,dy}{\int\limits_{-\infty}^{\infty}p_{\xi\eta}(x, y)\,dy}\Biggl|_{x=\xi},
\end{multline*}
где $p_{\xi\eta} (x, y)$ --- известная плотность.

\paragraph{Частные случаи.} \textsc{Гауссовское распределение.}
Если $(\xi, \eta)$ --- гауссовский вектор, то
\begin{align*}
  \hat{\eta} &= M(\eta \mid \xi) = \varphi(\xi) = M\eta + \dfrac{\cov(\xi,
  \eta)}{D\xi} (\xi-M\xi), \\
    \Delta &= M(\eta - M(\eta\mid\xi))^2 = D\eta (1 - r_{\xi\eta}^2).
\end{align*}

\textsc{Многомерное гауссовское распределение.}
Пусть $(\bar{\xi}, \bar{\eta})$ гауссово. Тогда
\begin{align*}
  \hat{\bar{\eta}} &= M(\bar{\eta} \mid \bar{\xi}) = M\bar{\eta} +
  \Sigma_{\bar{\eta} \bar{\xi}} \Sigma_{\bar{\xi}}^{-1} (\bar{\xi} -
  M\bar{\xi}), \\
  \Delta &= M(\bar{\eta} - M(\bar{\eta} \mid \bar{\xi}))(\bar{\eta} -
  M(\bar{\eta} \mid \bar{\xi}))^{\mathsf T}
  = \ldots = \Sigma_{\bar{\eta}} - \Sigma_{\bar{\eta}\bar{\xi}} \Sigma_{\bar{\xi}}^{-1} \Sigma_{\bar{\xi} \bar{\eta}}.
\end{align*}

\begin{ex}\label{ex-bernoulli-with-random-parameter}
  $\xi \sim \mathscr{R}[0, 1]$; $n$ --- число опытов с вероятностью успеха $\xi$; $\eta
  \sim \text{Bernoulli}(\xi)$ --- число успехов. Требуется найти $ P(\eta = j)
  $, $ j = 0, \ldots, n $.

  Тогда 
  \[
    P(\eta = j \mid \xi = x) = C_n^j x^j (1-x)^{n-j}
    \Rightarrow
    P(\eta = j \mid \xi) = C_n^j \xi^j (1-\xi)^{n-j}. 
    % M(\eta \mid \xi = x) = nx \Rightarrow M(\eta \mid\xi) = n\xi.
  \]
  % Причём интуитивно хотелось бы, чтобы $M(\eta \mid \xi = x) = n\cdot x$.
  % И тогда получим, что $M(\eta \mid \xi) = n \xi$.
  Хочется, чтобы $M\eta = MM(\eta \mid \xi)$.
\end{ex}

\begin{definition}[условная вероятность относительно разбиения]
  Пусть дано конечное разбиение $ \mathscr{D} = \{D_j\} $, $ \sum_j D_j = \Omega
  $. Тогда \textsl{случайная величина}\footnote{Символ зависимости $
  P(A\mid\mathscr{D}) = P(A\mid\mathscr{D})(\omega) $ опускается.} $ P(A \mid \mathscr{D}) = \sum_j P(A\mid
  D_j) I(D_j)$ называется \emph{условной вероятностью события $ A $ относительно
  разбиения $ \mathscr D $}.
\end{definition}

\begin{definition}[условная вероятность относительно СВ]
  Пусть $\xi$ --- простая случайная величина (измеримая функция, принимающая
  конечное множество значений):
  $\xi(\omega) = \sum\limits_{j=1}^k x_j I_{D_j}(\omega)$, где
  $\mathscr{D} = \left\{ D_j \right\} $ -- конечное разбиение пространства элементарных
  исходов ($\sum_j D_j = \Omega$).

Тогда \textsl{случайная величина}
\[
  P(A \mid \xi) = P(A \mid \mathscr D) = \sum\limits_{j=1}^k P(A\mid
  D_j) I_{D_j} = \sum_{j=1}^k P(A\mid \xi = x_j)I_{D_j}
\]
называется \emph{условной вероятностью события $ A $
    относительно случайной
  величины $ \xi $}.
\end{definition}

Каждому разбиению $ \mathscr D $ соответствует порождённая им $
\sigma $-алгебра $ \mathscr A = \sigma(\mathscr D) $. Обратно, по каждой $ \sigma
$-алгебре $ \mathscr A $
восстанавливается единственное разбиение $
\mathscr D$ такое, что $ \sigma(\mathscr D) = \mathscr A $. Иными словами,
имеется взаимно однозначное соответствие между $ \sigma $-алгебрами и
разбиениями.

\begin{definition}[условная вероятность относительно конечной $ \sigma
  $-алгебры]
  \emph{Условной вероятностью события $ A $ относительно $ \sigma $-алгебры $
  \mathscr A $} называется \textsl{случайная величина} $ P(A\mid \mathscr A) =
  P(A\mid \mathscr{D}) $, где разбиение $ \mathscr{D} $ соответствует $ \sigma
  $-алгебре $ \mathscr A $ ($ \sigma(\mathscr D) = \mathscr A $).
\end{definition}

\paragraph{Свойства условной вероятности относительно разбиения.} Заметим, что
  \begin{enumerate}
    \item $\mathscr{D} = \Omega \Rightarrow P(A \mid \mathscr{D}) = P(A\mid \Omega) I_\Omega = P(A)$;
    \item $MP(A \mid \mathscr{D}) = \sum\limits_{j=1}^k P(A \mid D_j) M(I_{D_j}) =
      \sum\limits_{j=1}^k P(A\mid D_j) P(D_j) = P(A)$. 
      Это свойство мы будем пытаться
      сохранить и
      при определении математического ожидания относительно $\sigma$-алгебры.
  \end{enumerate}

% Согласно второму свойству, в примере \ref{ex-bernoulli-with-random-parameter} теперь несложно
% получить, что 

\addtocounter{ex}{-1}
\begin{ex}[продолжение]
\begin{multline*}
  P(\eta = j) = MP(\eta = j \mid \xi) = MC^j_n\xi^j(1-\xi)^{n-j} =
  \int\limits_{-\infty}^{+\infty}g(x) p_{\xi}(x)\,dx = \\
  = \int\limits_{0}^{1}C_n^jx^j(1-x)^{n-j}\,dx = C^j_n
  \int\limits_{0}^{1}x^j(1-x)^{n-j}\,dx
  = C^j_n B(j+1, n-j+1) = \\
  = \frac{n!}{j!(n-j)!} \cdot
  \frac{\Gamma(j+1)}{\Gamma(n+2)} = \frac{n!}{j!(n-j)!}\cdot
  \frac{j!(n-j)!}{(n+1)!} = \frac{1}{n+1}.
\end{multline*}
%TODO: чего-то не хватает там где гамма-функции
\end{ex}

Тогда  
\[
  M\eta = \sum_{j=0}^n j P(\eta = j) = \frac{1}{n+1}\sum_{j=0}^n j =
  \frac{1}{n+1} \cdot \frac{n(n+1)}{2} = \frac{n}{2}.
\]



% \begin{definition}[УМО относительно разбиения]
%   Пусть $\mathscr{D} = \left\{ D_j \right\} $ --- конечное разбиение
%   пространства элементарных
%   исходов ($\sum_j D_j = \Omega$). 
% \end{definition}

% \begin{definition}[УМО относительно конечной алгебры]
%   Пусть $\mathscr{A}$ --- конечная алгебра. Тогда, согласно теореме из курса
%   функ. анализа, 
%   она порождается конечным разбиением $\mathscr{D}$. Тогда 
% \end{definition}

\begin{definition}[УМО относительно случайной величины]
  Пусть теперь $\xi$ и $\eta$ --- простые случайные величины:
  $\xi = \sum_j x_j I_{D_j}$, $\eta = \sum_i y_i I_{A_i}$.
  Тогда УМО равно
  \begin{multline*}
    M(\eta \mid \xi) = \sum_j \sum_i y_i P(A_i \mid D_j) I_{D_j} = \\ =
    \sum_j \sum_i y_i M(I_{A_i} \mid D_j) I_{D_j} = 
    \sum_j M \bigg( \sum_i y_i I_{A_i} \, \Big| \, D_j \bigg) I_{D_j}
    = \sum_j M(\eta \mid D_j) I_{D_j}.
  \end{multline*}
  Аналогично, меняя порядок суммирования, получим $ M(\eta\mid\xi)= \sum_i y_i
  P(A_i \mid \mathscr{D}) $.
\end{definition}

\paragraph{Свойства.}
\begin{enumerate}
  \item \textsc{Линейность}. $M(\alpha_1 \eta_1 + \alpha_2 \eta_2 \mid \mathscr{A}) =
      \alpha_1 M(\eta_1 \mid \mathscr{A}) + \alpha_2 M(\eta_2 \mid \mathscr{A})$;
  \item $M(C \mid \mathscr{A}) = C$ ($ C $ --- константа);
  \item $MM(\eta\mid  \mathscr{A}) = M\eta$.
    \begin{proof}
      Пусть $\mathscr{A}$ порождена разбиением $\mathscr{D} = D_1 + D_2 + \dots
      + D_k$. Тогда
      \[
        MM(\eta \mid  \mathscr{A}) = M \sum_i y_i P(\eta = y_i \mid
        \mathscr{A}) = \sum_{i=1}^l y_i MP(\eta = y_i \mid \mathscr{A}) =
        \sum_{i=1}^l y_i P(\eta=y_i) = M\eta.
      \]
    \end{proof}

  \item \begin{definition}
      Говорят, что СВ $\eta$ \emph{измерима относительно $\mathscr{A}$ ($
      \xi, \mathscr{D}$}), если
      $A_{\eta} \subseteq \mathscr{A}$ ($A_\eta \subseteq A_\xi$, $ A_\eta
      \subseteq A_{\mathscr D}) $.
    \end{definition}

    Тогда $M(\eta \mid  \mathscr{A})$ измеримо относительно $\mathscr{A}$:
      $M(\eta \mid  \mathscr{A}) = \sum M(\eta \mid  D_j) I_{D_j}$.

    \item Если $\zeta$ измерима относительно $\mathscr{A}$, то $M(\eta \zeta
      \mid  \mathscr{A}) = \zeta M(\eta \mid  \mathscr{A})$.
    \begin{proof}
      $\xi = \sum_j x_j I_{D_j}$, $\zeta = \sum_s z_s I_{D_s}$, $\eta = \sum_i y_i I_{A_i}$.

      Тогда левая часть:
      \begin{multline*}
        M(\eta\zeta \mid  \mathscr{A}) = M \bigg( \sum_i \sum_s y_i z_s I_{A_i
        D_s} \, \Big| \,  \mathscr{A} \bigg)
        = \sum_i \sum_s y_i z_s M ( I_{A_i D_s} \mid  \mathscr{A} ) = \\
        = \sum_i \sum_s y_i z_s M \bigg( \sum_j M(I_{A_i D_s} \mid  D_j) I_{D_j}
          \bigg) 
        = \sum_i \sum_s y_i z_s P(A_i \mid  D_s) I_{D_s}.
      \end{multline*}

      Правая часть:
      \[
        \zeta M(\eta \mid  \mathscr{A}) = \sum_s z_s I_{D_s} \sum_i y_i \sum_j
        P(A_i \mid  D_j) I_{D_j}
        = \sum_s z_s I_{D_s} \sum_i y_i P(A_i \mid  D_s).
      \]
    \end{proof}

  \item $\mathscr{A}_1 \subseteq \mathscr{A}_2 \Rightarrow M(\eta \mid
    \mathscr{A}_1) = M( M(\eta \mid  \mathscr{A}_2) \mid  \mathscr{A}_1)$;

  \item Если $\eta$ не зависит от $\xi$ (от $\mathscr{A}$), то $M(\eta \mid  \mathscr{A}) = M\eta$.
\end{enumerate}

\begin{theorem}[Радон -- Никодим]\label{theorem-radon-nikodim}
  Для множества, системы подмножеств и меры $(X, \mathscr{A}, \mu)$ назовём
  \emph{зарядом}
  некоторый интеграл $\Phi(B) = \int_B f(x) \mu(dx)$ (можно мыслить себе как новую меру).

  Если $(\mu(B) = 0 \Rightarrow \Phi(B) = 0)$ ($\Phi$ непрерывна относительно
  меры $\mu$),
  то существует такая функция $ \tilde f $, что 
  $\Phi(B) = \int_B \tilde f(x) dx$, где $\tilde f$ --- измеримая относительно
  меры $\mu$.

  Функцию $\tilde f$ также называют производной Радона -- Никодима.
\end{theorem}

\begin{definition}[Общее определение УМО]
  Для вероятностного пространства $(\Omega, \mathscr{A}, P)$ 
  $\Phi(B) = \int_B \eta(\omega) P(d\omega)$, причем имеет место $P(B) = 0
  \Rightarrow \Phi(B) = 0 $. Тогда по теореме \ref{theorem-radon-nikodim}
  существует $\hat{\eta}$ --- измеримая относительно $\mathscr{A}$, такая что
  $\hat{\eta} (\omega) \equiv M(\eta \mid  \xi)$.
\end{definition}

\begin{ex}
  Если $\xi$ и $\eta$ -- простые СВ, то 
  для любого $ t $
  \[
    \Phi(D_t) = \int_{D_t} \eta(\omega) P(d\omega) = \sum_i y_i P(A_i D_t).
  \]
  С другой стороны
  \[
    \int_{D_t} M(\eta \mid  \xi) P(d\omega) = \int_{D_t} \sum_j \sum_i y_i
    P(A\mid D_j) I_{D_j} P(d\omega)
    = \sum_i y_i P(A_i\mid D_t) P(D_t) = \sum_i y_i P(A_i D_t).
  \]
\end{ex}




% $P(\eta \mid  \mathscr{A}) \equiv M(I_A \mid  \mathscr{A})$

