\section{Лекция 1 -- 2024-02-09}
\subsection{Случайный процесс}
\begin{definition}
  Пусть на вероятностном пространстве $(\Omega, \mathscr A, \mathsf P)$ задана совокупность случайных величин
  $\xi = \xi(\omega, t),\ t \in T$, называемая \emph{случайным процессом}. При этом параметр 
  $t$ интерпретируется как время.

  \begin{itemize}[label=--]
    \item Если $T = \mathbb{N}$, то имеем процесс с \emph{дискретным временем};
    \item Если $T = \mathbb{R}$, то процесс с \emph{непрерывным временем};
    \item Если СВ $\xi=\xi(\omega, t)$ дискретного типа (то есть принимает не
      более чем счётное количество значений), то имеем процесс с \emph{дискретными состояниями};
    \item Если СВ $\xi$ непрерывного типа, то получаем случайный процесс с \emph{непрерывными состояниями}.
  \end{itemize}

  При любом фиксированном $t \in T$ функция $\xi(t, \omega)$ --- случайная
  величина (измеримая функция), называемая \emph{сечением}.

  При любом фиксированном $\omega$ функция $\xi(t, \omega)$ называется \emph{траекторией}.
\end{definition}


\subsection{Марковская цепь}
  Пусть некоторая физическая система может в некоторый момент времени находиться в одном из дискретных состояний
  $\{S_i\}_{i=1}^m$. При этом в моменты времени $t \in \mathbb{N}$ она может случайным образом
  переходить в другие состояния. Введём случайные величины $\xi_j$ так, чтобы если система
  находится в момент времени $j$ в состоянии $S_k$, то $\xi_j = k$.

\begin{definition}
  \emph{Марковской цепью} называется случайный процесс $\{\xi_t(\omega)\}$ с дискретным временем
  $t \in \mathbb{N} \cup \left\{ 0 \right\} $ и с дискретным множеством состояний
  $\mathscr{S} = \left\{ S_1, S_2, \dots, S_m \right\} $, такой что для любого
  натурального $ n > 1 $
  \[
    P(\xi_n = j \mid \xi_{n-1} = i, \xi_{n-2} = i_{n-2}, \xi_0 = i_0) =
    P(\xi_n=j \mid \xi_{n-1} = i) =: p_{ij}^n.
  \]
  Таким образом, состояния марковской цепи \textsl{не зависят от далёкого
  прошлого}.
\end{definition}

\begin{ex}
  Пусть $\eta_1, \eta_2, \dots, \eta_n$ --- независимые с.в. (и пускай они также целочисленные),
  тогда $\xi_n = \sum\limits_{k=1}^n \eta_k$ есть марковская цепь.

  В самом деле,
  \begin{multline*}
    P(\xi_n = j \mid \xi_{n-1} = i, \xi_{n-2} = i_{n-2}, \dots, \xi_1 = i_1)
    =\\=
    \dfrac{P(\xi_n = j, \xi_{n-1} = i, \xi_{n-2} = i_{n-2}, \dots, \xi_1 = i_1)}{P(\xi_{n-1} = i_{n-1}, \xi_{n-2} = i_{n-2}, \dots, \xi_1 = i_1)}
    = \dfrac{P(\eta_n = j-i, \xi_{n-1}=i, \dots, \xi_1 = i_1 )}{P(\xi_{n-1} = i_{n-1}, \xi_{n-2} = i_{n-2}, \dots, \xi_1 = i_1)}
    =\\= \dfrac{P(\eta_n = j-i) \cdot P(\xi_{n-1}=i, \dots, \xi_1 = i_1 )}{P(\xi_{n-1} = i_{n-1}, \xi_{n-2} = i_{n-2}, \dots, \xi_1 = i_1)}
    = P(\eta_n = j-i).
  \end{multline*}
\end{ex}


\paragraph{Свойства траекторий.}
\begin{enumerate}
  \item $P(\xi_{n+l} = i_{n+l}, \dots, \xi_n=j \mid \xi_{n-1}=i, \xi_{n-2} =
    i_{n-2}, \dots, \xi_0 = i_0) = P(\xi_{n+l} = i_{n_l}, \dots, \xi_n = j \mid \xi_{n-1} = i)$.
    \emph{Доказывается} по индукции.

  \item $P(\xi_{n+l} \in A_{n+l}, \dots, \xi_n\in A_{n} \mid \xi_{n-1} = i,
    \xi_{n-2} \in B_{n-2}, \dots, \xi_0 \in B_0) = P(\xi_{n+l} \in A_{n+l},
    \dots, \xi_n \in A_n \mid \xi_{n-1} = i)$. \emph{Доказательство} проще, такая вероятность является суммой таких же вероятностей как в прошлом пункте.

  \item Для любых $n > n_r > n_{r-1} > \ldots > n_1 \geqslant 0$
    \[
      P(\xi_n = j \mid \xi_{n_r}=i, \xi_{n_{r-1}} = i_{n_{r-1}}, \dots, \xi_{n_1} =
      i_{n_1})
      = P(\xi_n=j \mid \xi_{n_r} = i).
    \]

  \item $A = \left( \xi_{n+l} \in A_{n+l}, \dots, \xi_n \in A_n \right)$ суть
    будущее,
    $B = \left( \xi_{n-2}\in B_{n_2}, \ldots, \xi_0 \in B_0 \right) $ суть далёкое прошлое.
    Тогда <<условное будущее не зависит от условного прошлого>>:
    \[
      P(A \cap B \mid \xi_{n-1} =i) = P(A \mid \xi_{n-1} = i) \cdot P(B \mid
      \xi_{n-1} = i).
    \]
    \begin{proof}
      \begin{multline*}
        P(A \cap B \mid \xi_{n-1} = i) = \dfrac{P(A, \xi_{n-1} = i, B)}{P(\xi_{n-1} = i)} 
        = \dfrac{P(A, \xi_{n-1} = i, B)}{P(\xi_{n-1} = i)} \cdot \dfrac{P(\xi_{n-1}=i, B)}{P(\xi_{n-1}=i, B)} = \\
        = P(A \mid \xi_{n-1}=i, B) \cdot P(B \mid \xi_{n-1}=i)
        = P(A \mid \xi_{n-1}=i) \cdot P(B \mid \xi_{n-1}=i).
      \end{multline*}
    \end{proof}
\end{enumerate}

\paragraph{Характеристики марковского процесса.}
\begin{enumerate}
  \item $\bar{p}(k) = \left( p_1 (k), p_2(k), \dots, p_m(k)\right)^{\mathsf T} $,
    где $p_j(k) = P(S_j^k) = P(\xi_k = j)$ --- вектор вероятностей состояний в
    момент $ k $.

  \item $P(\xi_k = j \mid \xi_{k-1} = i) =: p_{ij}^{k}$ --- переходные вероятности на $k$-ом шаге.
    $P^{(k)} = (p_{ij}^k)$ --- матрица перехода вероятности на $k$-ом шаге, она является
    \emph{стохастической}, то есть такой, что сумма элементов в каждой строке равна
    единице.
\end{enumerate}

\paragraph{Соотношения.}
\begin{enumerate}
  \item $I = P^{(k)} \cdot I$, где $I = \left( 1 , 1 , 1 \right)^{\mathsf T} $. 
    Данное соотношение является определением \emph{стохастической матрицы}.
    \begin{proof}
      \begin{multline*}
        1 = P(\Omega \mid S_{k-1}^i) = P\biggl(\sum_{j=1}^m S_k^j \mid
          S_{k-1}^i\biggl)
        = \\ =
        \sum_{j=1}^m P(S_k^j \mid S_{k-1}^i)
        = \sum_{j=1}^m P\left(\xi_k = j \mid \xi_{k-1}=i\right) = \sum_{j=1}^m p_{ij}^k.
      \end{multline*}
    \end{proof}

  \item $\bar{p} (k+1) ^{\mathsf T} = \bar{p}(k)^{\mathsf T} \cdot P^{(k)}$.
    \begin{proof}
      $\Omega = S_1^k + S_2^k + \ldots + S_m^k$, так как события несовместны.
    \[
      P(S_j^{k+1}) = \sum_{i=1}^m P(S_j^{k+1} \mid S_i^k) \cdot P(S_i^k)
      = \sum_{i=1}^m p_{ij}^k \cdot p_i(k).
    \]
    \end{proof}

  \item $\bar{p} (k+1)^{\mathsf T} = \bar{p}(0)^{\mathsf T} \cdot P^{(1)} P^{(2)} \cdot \ldots \cdot P^{(k)}$.
\end{enumerate}


\subsection{Однородные марковские цепи}
\begin{definition}
  Марковская цепь $\xi_k$ называется \emph{однородной}, если $p_{ij}^k =
  P(\xi_k=j \mid \xi_{k-1}=i)$ не
  зависит от $ k $.
\end{definition}
Для однородных цепей $\bar{p}(l+1)^{\mathsf T} = \bar{p}(l)^{\mathsf T} P$, а
$\bar{p}(l=1)^{\mathsf T} = \bar{p}(0)^{\mathsf T} P^{l+1}$.

\begin{theorem}[Колмогорова -- Чепмена]
  Пусть в однородной марковской цепи $p_{ij}^{(k)} = P(\xi_{l+k} = j \mid
  \xi_l=i)$. Обозначим
  $\mathbb{P}^{(k)} = (p_{ij}^k)$. Тогда имеет место соотношение
  \[
    \forall l, k \quad \mathbb{P}^{(k+l)} = \mathbb{P}^{(k)} \mathbb{P}^{(l)}.
  \]
\end{theorem}
% TODO дописать обратную теорему
\begin{proof}
  \begin{multline*}
    p_{ij}^{(k+l)} = P(\xi_{k+l}=j \mid \xi_0 = i)
    = P\biggl(\xi_{k+l}=j,\, \bigcup_{\alpha=1}^m (\xi_k=\alpha) \biggm| \xi_0 =
      i\biggl) = \\
    = \dfrac{\sum\limits_{\alpha=1}^m P(\xi_{k+l} = j, \xi_k = \alpha, \xi_0=i)}{P(\xi_0=i)}
    = \sum_{\alpha=1}^m \dfrac{P(\xi_{k+l} = j, \xi_k = \alpha, \xi_0=i)}{P(\xi_0=i)} \dfrac{P(\xi_k=\alpha, \xi_0=i)}{P(\xi_k=\alpha, \xi_0=i)} = \\
    = \sum_{\alpha=1}^m P(\xi_k=\alpha\mid\xi_0=i) P(\xi_{k+l}=j \mid \xi_k = \alpha, \cancel{\xi_0=i})
    = \sum_{\alpha=1}^m P_{i\alpha}^{(k)} P_{\alpha j}^{(l)}.
  \end{multline*}
\end{proof}

\subsection{Эргодическая цепь}

\begin{definition}
  Марковская цепь называется \emph{эргодической}, если для любого $ i $ существует и не зависит
  от $ i $ предел
  \[
    \lim_{n\to\infty} p_{ij}^{(n)} = \pi_{j}.
  \]
  Здесь $0 < \pi_j < 1$, $\sum\limits_{j=1}^m \pi_j = 1$.

  Вектор $\bm{\pi}$ называется \emph{финальным} (распределением).
\end{definition}

\textsc{Пояснение}.\hspace{.1em} В пределе получается, что матрица состоит из одинаковых строк, каждая из
которых совпадает с $\bm{\pi}^{\mathsf T}$.

\begin{definition}
  Распределение $\bm{\pi}$ называется \emph{стационарным}, если эти числа удовлетворяют
  системе
  \[
    \bm{\pi}^{\mathsf T} = \bm{\pi}^{\mathsf T} \cdot P
    \Leftrightarrow 
    \pi_j = \sum_\alpha \pi_\alpha p_{\alpha j}.
  \]
\end{definition}

\begin{theorem}
  Если марковская цепь $\xi_n$ имеет конечное множество состояний и существуют $0
  <\varepsilon < 1$,
  $n_0 \in \mathbb N$ такие, что $\min\limits_{i, j} p_{ij}^{(n_0)} \geqslant
  \varepsilon$, то цепь эргодическая, а
  финальные вероятности совпадают со стационарными.
\end{theorem}
\begin{proof}
  Обозначим как $m_j^{(n)} := \min\limits_i p_{ij}^{(n)}$, $M_j^{(n)} = \max\limits_i p_{ij}^{(n)}$ минимальный 
  и максимальный элементы в столбце. Докажем монотонное возрастание $m_{j}^{(n)}$ и монотонное
  убываение $M_j^{(n)}$. По теореме Колмогорова -- Чепмена
  \[
    m_{j}^{(n+1)} = \min_i p_{ij}^{(n+1)}
    = \min_i \sum_{\alpha=1}^m p_{i\alpha} \cdot p_{\alpha j}^{n} \geqslant 
    \min_i \sum_{\alpha=1}^m p_{i \alpha} m_j^{(n)}
    = m_j^{(n)}.
  \]
  Аналогично показывается, что $M_{j}^{(n+1)} \leqslant M_j^{(n)}$.

  % TODO выше сказано монотонное убывание (возрастание) соответствующих последовательностей
  % но мы доказали только невозрастание (неубывание)
  Выберем $\varepsilon = \min\limits_{i, j} p_{ij}^{(n_0)} > 0$.
  Видно, что $M_j^{(n)}-m_j^{(n)}$ монотонно убывает. Тогда
  \begin{multline*}
    p_{ij}^{(n+n_0)} = \sum_{\alpha=1}^m p_{i\alpha}^{(n_0)} p_{\alpha j}^{(n)}
    = \sum_{\alpha=1}^m (p_{ij}^{(n_0)} - \varepsilon p_{j \alpha}^{(n)}) p_{\alpha j}^{(n)}
      + \varepsilon \sum_{\alpha=1}^m p_{j \alpha}^{(n)} p_{\alpha j}^{(n)} \geqslant \\
    \geqslant \sum_{\alpha=1}^m (p_{i\alpha}^{(n_0)} - \varepsilon p_{j\alpha}^{(n)}) m_j^{(n)}
      + \varepsilon p_{jj}^{(2n)}
    = m_j^{(n)} (1-\varepsilon) + \varepsilon p_{jj}^{(2n)}.
  \end{multline*}
  Таким образом, $m_j^{(n+n_0)} \geqslant m_j^{(n)} (1-\varepsilon) + \varepsilon p_{jj}^{(2n)}$.
  
  Аналогично доказывается, что $M_j^{(n+n_0)} \leqslant M_j^{(n)}
  (1-\varepsilon) + \varepsilon p_{jj}^{(2n)}$.
  Тогда $M_{j}^{(n+n_0)} - m_j^{(n+n_0)} \leqslant (1-\varepsilon) (M_j^{(n)} - m_j^{(n)})$. 
  Тогда $M_j^{(n+kn_0)} - m_j^{(n+kn_0)} \leqslant (1-\varepsilon)^k (M_j^{(n)} - m_j^{(n)}) \to 0, k\to \infty$, то есть $M_{j}^{(n)} - m_j^{(n)} \to 0, n \to \infty$. По теореме о двух милиционерах
  $m_j^{(n)} \leqslant p_{ij}^{(n)} \leqslant M_j^{(n)}$.
\end{proof}

Обозначим $\lim\limits_{n\to\infty} p_{ij}^{(n)} =: \pi_j$, где $j = \overline{1, m}$. 

\begin{remark*}
  Обратное утверждение тоже верно, то есть если марковская цепь является эргодической, то найдется
  такое $n_0$, что $\min\limits_{i, j} p_{ij}^{(n_0)} > 0$.
\end{remark*}

\setcounter{corollary}{0}
\begin{corollary}
  Безусловные вероятности $\bar{p} (n)^{\mathsf T} = \bar{p}(0)^{\mathsf T} P^n \to
      \left(\pi_1 , \pi_2 , \dots , \pi_n \right)$ (для любого начального
      состояния!), так как матрица $P$ при возведении в степень стремится к
      \[
        P^n \to \begin{pmatrix}
          \pi_1 & \pi_2 & \dots & \pi_n \\
          \pi_1 & \pi_2 & \dots & \pi_n \\
          \dots \\
          \pi_1 & \pi_2 & \dots & \pi_n
        \end{pmatrix}.
      \]
    \end{corollary}

    \begin{corollary}
      Для нахождения финальных вероятностей необязательно искать предел матрицы,
      достаточно найти стационарные вероятности. Если $\bar{p}(n+1)^T = \bar{p}(n)^T \cdot P$,
      то для стационарной вероятности имеем уравнения
      \[
        \begin{cases}
          \vec{\pi}^T = \vec{\pi}^T \cdot P \Leftrightarrow \pi^T (P - E) = 0,\\
          \sum\limits_{k=1}^m \pi_k = 1.
        \end{cases}
      \]
      Первое уравнение есть однородная СЛАУ с $n$ уравнениями и $n$ неизвестными, но определитель
      матрицы этой СЛАУ равен нулю (единица всегда является собственным числом для стохастических матриц). 
      Пользуемся условием нормировки и получаем совместную СЛАУ.
      % TODO утверждение про собственное число требует проверки, но на семинаре нам такое говорили

      % TODO открытый вопрос: почему эта СЛАУ совместна?
  \end{enumerate}
\end{corollary}

